# -*- coding: utf-8 -*-
"""participation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eLa5busbFmQ2jYsiuefeFoVLeyQPvFWP
"""

# Installations + dependencies
!pip install tqdm
!pip install --upgrade pymupdf

# Connect to drive
from google.colab import drive
drive.mount('/content/drive')

# Get list of titles and initial dates from https://colab.research.google.com/drive/1xVLTukgLKr0vCRuHzarxi9CbysoxgC_7?usp=sharing
import pandas as pd
df2 = pd.read_excel('/content/drive/MyDrive/initial.xlsx')
df2['titles'] = df2['title'].str.upper()

# Check that folder of Participations exists
import os
folder_path = '/content/drive/MyDrive/SAP'
if os.path.exists(folder_path):
    os.chdir(folder_path)

# Create list of all PDFs that need to be scanned (get rid of non-readable with READABLE copy)
main = []
for root, _, files in os.walk('.', topdown=False):
    for file in files:
        filepath = os.path.join(root, file)
        keep_file = True
        for other_file in files:
            if ('readable') in os.path.basename(other_file).lower() and os.path.basename(file) != os.path.basename(other_file) and os.path.basename(file) in os.path.basename(other_file):
                  keep_file = False
                  break
        if not keep_file:
            continue
        single = [filepath, os.path.dirname(filepath), (os.path.basename(filepath))]
        main.append(single)

# Convert folder names to date objects and sort by folder
from datetime import datetime
df = pd.DataFrame(main, columns=['path', 'dir', 'file'])
df['date'] = df['dir'].str.split().str[0].str[2:].str.split('-').str[0]

def convert(date):
  try:
    return datetime.strptime(date, '%Y/%m')
  except:
    print(date)

df['date'] = df['date'].apply(convert)
df.sort_values(by=['date'], ascending=False)

# Function to find all of the films included in a Participation
import re
import fitz

def try_this(filepath):
    doc = fitz.open(filepath)
    long_text = ''
    for page in doc:
      long_text += page.get_text()
    pattern = r"PICTURE TITLE:\s+(.*?)\n"
    matches = re.findall(pattern, long_text)
    stripped_matches_set = {m.strip() for m in matches}
    if stripped_matches_set != 0:
      try:
        assert len(stripped_matches_set) * 2 + 4 >= len(doc), f'{len(stripped_matches_set)} compared to: {len(doc)} for {filepath}'
      except AssertionError as e:
        print(str(e))
    return stripped_matches_set

# Function to get the mailing and period date from the Participation
def scan_pdf(filepath):
    try:
      doc = fitz.open(filepath)
      text = doc[0].get_text().lower()
      return get_date(text)
    except Exception as e:
      print(e)
      print('Broken - ' + filepath)

def get_date(text):
    pattern = r"\b[a-z]+\s+\d{1,2},\s+\d{4}\b"  # Define the date pattern (example: "month day, year")
    matches = re.findall(pattern, text, re.IGNORECASE)
    if matches:
        format = "%B %d, %Y"
        return (datetime.strptime(matches[0].capitalize(), format), datetime.strptime(matches[1].capitalize(), format))
    else:
      return (None, None)

# Apply function for dates across all documents
df['temp'] = df['path'].apply(scan_pdf)

# Apply function for films across all documents using parallel computing
import multiprocessing
from tqdm import tqdm

def process_row(index, row):
    titles = try_this(row['path'])
    return titles

num_processes = multiprocessing.cpu_count()
pool = multiprocessing.Pool(processes=num_processes)
results = []
with tqdm(total=len(df)) as pbar:
    def update_progress(*_):
        pbar.update(1)
    for index, row in df.iterrows():
        result = pool.apply_async(process_row, args=(index, row), callback=update_progress)
        results.append(result.get())
pool.close()
pool.join()
df['titles'] = [result for result in results]

df.sort_values(by=['date'], ascending=False)

# processing for unreadable pdfs
'''
import shutil

destination_folder = "/content/drive/MyDrive/SAP/Unstructured"
def create_copy(filepath, dest_folder = destination_folder, new_filename=None):
    os.makedirs(dest_folder, exist_ok=True)
    file_name = os.path.basename(filepath)
    if new_filename is None:
        new_filename = file_name
    dest_path = os.path.join(dest_folder, new_filename)
    shutil.copy2(filepath, dest_path)
    print(f"Created a copy of {filepath} as {dest_path}")
    return dest_path

df1 = df[df['titles] == set()]
df1['copy'] = df1['path'].apply(create_copy)
'''

# apply ocr to unstructured pdfs
df.loc[df['titles'] == set(), 'path'] = '/content/drive/MyDrive/Unstructured/' + df.loc[df['titles'] == set(), 'file'].astype(str)
df.loc[df['titles'] == set(), 'temp'] = df.loc[df['titles'] == set(), 'path'].apply(scan_pdf)
df.loc[df['titles'] == set(), 'titles'] = df.loc[df['titles'] == set(), 'path'].apply(try_this)

df['mail'] = df['temp'].str[0]
df['period'] = df['temp'].str[1]

from datetime import timedelta

# duplicate rinse 1
df3 = pd.read_excel('/content/drive/MyDrive/finally.xlsx')
first_appearances = {}
for index, row in df.iterrows():
    titles = row['titles']
    m = row['mail']
    p = row['period']
    f = row['dir']
    f2 = row['file']
    for title in titles:
        if title not in first_appearances or (m is not None and m < first_appearances[title]['Mailing']):
            title = title.strip()
            if m < p:
                    m = m + timedelta(365)
            first_appearances[title] = {
                'Title': title,
                'Mailing': m,
                'Period': p,
                'Folder': f,
                'File': f2
            }

newdf = pd.DataFrame(first_appearances).transpose()
newdf.to_excel('films5.xlsx')

# duplicate rinse 2
df4 = pd.read_excel('/content/drive/MyDrive/SAP/films5.xlsx')
duplicates = df4[df4.duplicated(subset='titles', keep=False)]
min_indices = df4.groupby('titles')['mail'].idxmin()
filtered_df = df4.loc[min_indices]

# merge with film list
dfm = pd.merge(df2, filtered_df, on='titles', how='outer')
dfm = dfm.drop(['title', 'unstructured'], axis=1)
dfm.to_excel('final_v2.xlsx')